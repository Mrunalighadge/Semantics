# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WtOYVkh-XHab21jUNz4YJQL0dvyUbULw

# **1. Data Preparation**

###**1.1 Data Cleaning**
"""

# Import Necessary Libraries
import pandas as pd
import numpy as np
import re

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from pathlib import Path


# Define file paths
true_csv = Path('/content/drive/My Drive/P487_m/True.csv')
fake_csv = Path('/content/drive/My Drive/P487_m/Fake.csv')

true_news = pd.read_csv(true_csv, encoding='latin1', delimiter='\t', on_bad_lines='skip', quotechar='"', header=None, names=['title', 'text'])  # Added names for columns
fake_news = pd.read_csv(fake_csv, encoding='latin1', delimiter='\t', quotechar='"', header=None, names=['title', 'text'])  # Added names for columns



# Display the dataframes
print(true_news.head())
print(fake_news.head())



# Add a 'label' column to each dataset
fake_news['label'] = 0  # 0 for fake news
true_news['label'] = 1  # 1 for true news

# Combine datasets
news_data = pd.concat([fake_news, true_news], ignore_index=True)

# Shuffle the data
news_data = news_data.sample(frac=1, random_state=42).reset_index(drop=True)

# Display combined data info
print("\nCombined DataFrame Info:")
print(news_data.info())

"""###**1.2 Remove Missing Data**"""

# Check for missing values
missing_values = news_data.isnull().sum()
print("\nMissing Values in Each Column:")
print(missing_values)

# Drop rows with missing values
news_data = news_data.dropna().reset_index(drop=True)

news_data

"""###**1.3 Handle Duplicates**"""

# Check for duplicates values
duplicate_rows = news_data[news_data.duplicated(subset=['text'])]
print("\nDuplicate Rows:")
print(duplicate_rows)

# Drop rows with duplicates values
news_data.drop_duplicates(subset=['text'], inplace=True)
print("\nAfter Removing Duplicates:")
print(news_data.info())

"""###**1.4 Remove Non-Textual Content**"""

def clean_text(text):
    text = re.sub(r'\W', ' ', text)  # Remove special characters
    text = re.sub(r'\s+', ' ', text)  # Remove extra whitespace
    return text.strip()

news_data['text'] = news_data['text'].apply(clean_text)

"""###**1.5 Lowercase Conversion**"""

# Convert the 'text' columns to lowercase
news_data['text'] = news_data['text'].str.lower()
print(news_data['text'])



"""# **2. Exploratory Data Analysis (EDA)**"""

import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter

"""###**2.1 Analyze Class Distribution**"""

# Bar Graph of fake news and real news counts
g = sns.catplot(x='label', data=news_data, kind='count', palette="pastel")

# Add titles and axis labels
plt.title('Bar Graph of Fake News and Real News Counts')
plt.xlabel('News Type')
plt.ylabel('Count of News Type')

# Set the x-tick labels to more readable class names
# Get the current x-tick locations
x_ticks = g.axes[0, 0].get_xticks()

# Set the x-tick labels at the corresponding locations
g.axes[0, 0].set_xticklabels(["Fake", "True"])

# Add labels on top of the bars
for ax in g.axes.flat:
    ax.bar_label(ax.containers[0], fontsize=12)

# Show the plot
plt.show()

"""###**2.2 Text Length Analysis**"""

news_data['text_length'] = news_data['text'].apply(len)
sns.histplot(news_data['text_length'], kde=True)
plt.title('Text Length Distribution')
plt.show()

"""###**2.3 Word Frequency Analysis**"""

all_words = ' '.join(news_data['text'])
word_freq = Counter(all_words.split()).most_common(20)

# Visualize Word Cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Most Common Words')
plt.show()

"""####**2.4 Pie Chart of fake news and real news percentage**"""

# Get the number of unique labels
num_labels = len(news_data["label"].value_counts())

# Create an explode list with the correct length
explode = [0] * num_labels  # Creates a list of zeros with length num_labels

plt.pie(news_data["label"].value_counts().values,
        explode=explode,  # Use the explode list with the correct length
        labels=news_data["label"].value_counts().index,
        autopct='%1.1f%%',  # Show percentage with one decimal place
        colors=['LightBlue', 'LightPink'])  # Custom colors for the slices

# Set the title and label
plt.title('Fake News vs Real News Percentage')
plt.xlabel('News Type (1 = Real, 0 = Fake)')

# Show the plot
plt.show()

"""####**2.5 Distribution of The Subject by Real and Fake Data**

# **3. Text Preprocessing**

     Prepare text for vectorization and machine learning.

###**3.1 Tokenization**

Split text into individual words or tokens.
"""

import nltk
nltk.download('punkt_tab')

from nltk.tokenize import word_tokenize
news_data['tokens'] = news_data['text'].apply(word_tokenize)

"""###**3.2 Stopwords Removal**

Remove common words (e.g., "and", "is", "the") using predefined stopword lists.

"""

import nltk

# Download the 'stopwords' dataset
nltk.download('stopwords')

from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))
news_data['tokens'] = news_data['tokens'].apply(lambda x: [word for word in x if word not in stop_words])

"""###**3.3 Lemmatization**

Reduce words to their base forms to normalize text (e.g., "running" â†’ "run").

"""

from nltk.stem import WordNetLemmatizer

# Download WordNet dataset
import nltk
nltk.download('wordnet')

# Now initialize and use the lemmatizer
lemmatizer = WordNetLemmatizer()
news_data['tokens'] = news_data['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])

"""###**3.4 Rejoin Tokens into Processed Text**

Combine tokens back into processed text for model input.
"""

news_data['processed_text'] = news_data['tokens'].apply(lambda x: ' '.join(x))

#Inspect processed text
print(news_data['processed_text'].head())

"""# **4. Feature Extraction**
        
    Feature extraction is about converting the preprocessed text into numerical representations that a machine learning model can process.

###**4.1 Vectorization**

**TF-IDF Vectorizer:**

Assigns weights to words based on their frequency and importance.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Assuming `news_data` contains the processed text and labels
# `processed_text` is the column with preprocessed news articles
# `label` is the target column (0 for fake, 1 for real)

# Splitting the dataset into training and testing sets
X = news_data['processed_text']
y = news_data['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))

# Apply TF-IDF transformation
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a Multinomial Naive Bayes classifier
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# Predict on the test set
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""# **5. Model Building**

###**5.1 Classification Models**
"""

# Importing Libraries
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""**a) Logistic Regression :**

- Train and evaluate the Logistic Regression model.
"""

# Assuming `news_data` contains the processed text and labels
# `processed_text` is the column with preprocessed news articles
# `label` is the target column (0 for fake, 1 for real)

# Splitting the dataset into training and testing sets
# Use stratify parameter to ensure class distribution is maintained in splits
X = news_data['processed_text']
y = news_data['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ... rest of your code ...


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Train Logistic Regression classifier
# Adjust max_iter for convergence (especially with large datasets)
lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train_tfidf, y_train)  # X_train_vec is the vectorized training data

# Predict on the test set
y_pred_lr = lr_model.predict(X_test_tfidf)  # X_test_vec is the vectorized test data

# Calculate metrics
lr_accuracy = accuracy_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr, average='weighted')

# Evaluate
print("\nLogistic Regression Results:")
print(f"Accuracy: {lr_accuracy:.2f}")
print(f"F1-Score: {lr_f1:.2f}")
print(classification_report(y_test, y_pred_lr))

"""**b) Naive Bayes:**

- Train and evaluate the Naive Bayes model.
"""

from sklearn.naive_bayes import MultinomialNB

# Train Naive Bayes classifier
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)

# Predict on test set
y_pred_nb = nb_model.predict(X_test_tfidf)

# Calculate Metrics
nb_accuracy = accuracy_score(y_test, y_pred_nb)
nb_f1 = f1_score(y_test, y_pred_nb, average='weighted')

# Evaluate
print("Naive Bayes Results:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_nb)}")
print(classification_report(y_test, y_pred_nb))

"""**c) Support Vector Machine (SVM):**

- Train and evaluate the SVM model.

"""

from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Train SVM classifier with linear kernel
svm_model = LinearSVC(C=1.0, max_iter=1000)  # You can adjust C and max_iter as needed
svm_model.fit(X_train_tfidf, y_train)

# Predict on test set
y_pred_svm = svm_model.predict(X_test_tfidf)

# Calculate Metrics
svm_accuracy = accuracy_score(y_test, y_pred_svm)
svm_f1 = f1_score(y_test, y_pred_svm, average='weighted')

# Evaluate
print("\nSVM Results:")
print(f"Accuracy: {svm_accuracy:.2f}")
print(f"F1-Score: {svm_f1:.2f}")
print(classification_report(y_test, y_pred_svm))

"""**d) XGBoost:**

- Train and evaluate the XGBoost model.
"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

# Initialize XGBoost
xgb_model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    use_label_encoder=False,  # Avoid deprecation warnings
    eval_metric='logloss'     # Specify evaluation metric
)

# Train the model
xgb_model.fit(X_train_tfidf, y_train)  # Ensure X_train_tfidf is vectorized data

# Predictions
y_pred_xgb = xgb_model.predict(X_test_tfidf)  # Use the same vectorizer for test data

# Calculate Metrics
xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
xgb_f1 = f1_score(y_test, y_pred_xgb, average='weighted')

# Evaluation
print("\nXGBoost Performance:")
print(f"Accuracy: {xgb_accuracy:.2f}")
print(f"F1-Score: {xgb_f1:.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_xgb))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_xgb))

"""**e) Decision Tree:**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score

# Train Decision Tree classifier
dt_model = DecisionTreeClassifier(random_state=42)  # Random state ensures reproducibility
dt_model.fit(X_train_tfidf, y_train)  # Fit the model on the TF-IDF vectorized training data

# Predict on the test set
y_pred_dt = dt_model.predict(X_test_tfidf)

# Calculate Metrics
dt_accuracy = accuracy_score(y_test, y_pred_dt)
dt_f1 = f1_score(y_test, y_pred_dt, average='weighted')

# Evaluate the model
print("\nDecision Tree Results:")
print(f"Accuracy: {dt_accuracy:.2f}")
print(f"F1-Score: {dt_f1:.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_dt))

"""**f) Random Forest:**"""

# Import necessary libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score

# Train Random Forest classifier
rf_model = RandomForestClassifier(random_state=42, n_estimators=100)
rf_model.fit(X_train_tfidf, y_train)  # Fit model on training data

# Predict on test set
y_pred_rf = rf_model.predict(X_test_tfidf )

# Calculate Metrics
rf_accuracy = accuracy_score(y_test, y_pred_rf)  # Accuracy of the model
rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')  # F1-score for the model

# Evaluate
print("\nRandom Forest Results:")
print(f"Accuracy: {rf_accuracy}")
print(f"F1-Score: {rf_f1}")
print(classification_report(y_test, y_pred_rf))

"""**g) LightGBM (LGBM):**"""

# Import necessary libraries
import lightgbm as lgb
from sklearn.metrics import accuracy_score, classification_report, f1_score

# Convert features to float32 to avoid type errors
X_train_vec = X_train_tfidf.astype('float32')
X_test_vec = X_test_tfidf.astype('float32')

# Train LightGBM classifier
lgb_model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
lgb_model.fit(X_train_vec, y_train)  # Fit model on training data

# Predict on test set
y_pred_lgb = lgb_model.predict(X_test_vec)

# Calculate Metrics
lgb_accuracy = accuracy_score(y_test, y_pred_lgb)  # Accuracy of the model
lgb_f1 = f1_score(y_test, y_pred_lgb, average='weighted')  # F1-score for the model

# Evaluate
print("\nLightGBM Results:")
print(f"Accuracy: {lgb_accuracy}")
print(f"F1-Score: {lgb_f1}")
print(classification_report(y_test, y_pred_lgb))

"""###**5.2 Evaluate Model Performance**

**a) Logistic Regression:**
"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr)
plt.show()

"""**b) Naive Bayes:**"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_nb)
plt.show()

"""**c) Support Vector Machine (SVM):**"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_svm)
plt.show()

"""**d) XGBoost:**"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_xgb)
plt.show()

"""**e) Decision Tree:**"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_dt)
plt.show()

"""**f) Random Forest:**"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf)
plt.show()

"""**g) LightGBM (LGBM):**"""

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lgb)
plt.show()

"""###**5.3 Summary of Results**"""

# Summary of results
results = pd.DataFrame({
    'Model': [ 'Naive Bayes',  'Decision Tree', 'Random Forest', 'LightGBM'],
    'Accuracy': [ nb_accuracy, dt_accuracy, rf_accuracy, lgb_accuracy],
    'F1-Score': [ nb_f1,  dt_f1, rf_f1, lgb_f1]
})

print("\nModel Performance Comparison:")
print(results)

pip install streamlit

# Train Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_tfidf, y_train)

import gzip
import pickle

# Save compressed pickle file
with gzip.open('fake_news_model.pkl.gz', 'wb') as compressed_file:
    pickle.dump(model, compressed_file)

# Load compressed pickle file
with gzip.open('fake_news_model.pkl.gz', 'rb') as compressed_file:
    model = pickle.load(compressed_file)




import pickle
with open('random_forest_model.pkl', 'wb') as model_file:
    pickle.dump(rf_model, model_file)

with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:
    pickle.dump(tfidf_vectorizer, vectorizer_file)

